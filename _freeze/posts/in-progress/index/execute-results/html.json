{
  "hash": "6c8c861238609b928dacec1d11135444",
  "result": {
    "markdown": "---\ntitle: \"Untitled\"\n---\n\n\n## Support All Ways of Thinking\n\nWhat is the reasoning behind this post? I love what I do, and can get an abundance of energy from projects that I'm working on. That being said, it's incredibly frustrating using a specific tool, when I would enjoy and work faster in another tool. \n\n#### Insert Tired Python vs R Debate\n\nNothing will earn an auto-mute from me on Twitter faster than seeing a Python vs R debate. They are both fantastic tools, and each have their own strengths and weaknesses. What I find most important is to focus on how they can present themselves to a particular user. A feature I see as beneficial from R could be detrimental to another user, for a myriad of reasons. \n\nI support that setting up infrastructure which enables data professionals to use their tool of choice will help flourish the flow of ideas and analysis. Especially early on in the data exploration phase. \n\n\n## Use Case\n\nFor reasons I won't get into here, at work I needed to connect to a database in Python using existing code. From there I could stay in that environment, but I wanted to be able to work with the data in a tool that is better suited for me in R.\n\nI was familiar with the [Apache Arrow](https://arrow.apache.org/) project, and the best source I found for understanding from an R user's perspective was [This Blog Post](https://blog.djnavarro.net/posts/2022-09-09_reticulated-arrow/). Danielle, at the time of writing, is a Developer Advocate at [Voltron Data](https://voltrondata.com/). A couple of statements from their website *\"Bridging Languages, Hardware, and People\"* along with *\"Accelerate Success with the Apache Arrow Ecosystem\"*. \n\n#### Minor Improvements\n\nDanielle covers all the foundations of [reticulate](https://rstudio.github.io/reticulate/), [Apache Arrow](https://arrow.apache.org/docs/index.html), and getting everything set up. I was able to apply it for my use case, with one drawback. The post mentions `r_to_py()`, and when I tried to use `py_to_r()`, I had no success. \n\n## Setup\n\n#### DuckDB\n\n[DuckDB](https://duckdb.org/) is awesome. Check it out. \n\nAgain, this is outside the scope of this post. There is already an extensive amount of coverage on how the DB works, what it's best for, and examples of how to use it. I mainly chose this because of it's integration into the Apache Arrow ecosystem. \n\nThere are many different interfaces to install DuckDB found here: [DuckDB Install](https://duckdb.org/#quickinstall).\n\n#### Reticulate Config\n\nUsing Reticulate, we can integrate Python and R. At work, I created an R package that would allow me to use our established pipelines in python and analyze the data in R with Reticulate. \n\nThe intended user is already someone that is familiar with R (after all what is the point of all of this if you don't already have **{dplyr}** installed?!). \n\n\n::: {.cell}\n\n```{.r .cell-code}\nif(!require('reticulate')) install.packages('reticulate') \nif(!require('arrow')) install.packages('arrow') \nif(!require('tictoc')) install.packages('tictoc') # only needed for benchmark\n\nif (!reticulate::virtualenv_exists(\"demo_env\")) {\n  reticulate::virtualenv_create(\n    'demo_env'\n    , packages = c('duckdb'\n                   , 'pandas==2.0'\n                   , 'polars'\n                   , 'pyarrow'\n                   , 'scikit-learn'\n                   )\n    )\n}\n\nreticulate::use_virtualenv('demo_env')\n```\n:::\n\n\n## <Insert Your DB Here>\n\nAs mentioned above, DuckDB is used for the toy use case. For my workflow in particular, this is where I would connect to our data with the existing Python codebase. The idea is to not re-invent the wheel for something that is already working. Rather, build a tire for that wheel that will make you go faster. \n\nBelow creates a toy dataset from Scikit-Learn datasets, [Wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html).\n\n*Note: You can make this virtual environment lighter by not having to install sklearn and duckdb.*\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport duckdb \nimport pandas as pd\nimport polars as pl\nimport pyarrow as pa\nfrom sklearn import datasets\n\ndata = datasets.load_wine(as_frame=True)['data']\n\n# Create a DuckDB connection\n#conn = duckdb.connect(\"posts/in-progress/data/demo.db\")\nconn = duckdb.connect(\"data/demo.db\")\n\n# Create toy data\nduckdb.sql(\"\"\"\nDROP TABLE IF EXISTS my_table;\nCREATE TABLE my_table AS SELECT * FROM data;\nINSERT INTO my_table SELECT * FROM data;\n\"\"\")\n\n# Check that table is created\nduckdb.sql(\"SELECT * FROM my_table LIMIT 10;\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n┌─────────┬────────────┬────────┬───────────────────┬───┬─────────────────┬────────┬──────────────────────┬─────────┐\n│ alcohol │ malic_acid │  ash   │ alcalinity_of_ash │ … │ color_intensity │  hue   │ od280/od315_of_dil…  │ proline │\n│ double  │   double   │ double │      double       │   │     double      │ double │        double        │ double  │\n├─────────┼────────────┼────────┼───────────────────┼───┼─────────────────┼────────┼──────────────────────┼─────────┤\n│   14.23 │       1.71 │   2.43 │              15.6 │ … │            5.64 │   1.04 │                 3.92 │  1065.0 │\n│    13.2 │       1.78 │   2.14 │              11.2 │ … │            4.38 │   1.05 │                  3.4 │  1050.0 │\n│   13.16 │       2.36 │   2.67 │              18.6 │ … │            5.68 │   1.03 │                 3.17 │  1185.0 │\n│   14.37 │       1.95 │    2.5 │              16.8 │ … │             7.8 │   0.86 │                 3.45 │  1480.0 │\n│   13.24 │       2.59 │   2.87 │              21.0 │ … │            4.32 │   1.04 │                 2.93 │   735.0 │\n│    14.2 │       1.76 │   2.45 │              15.2 │ … │            6.75 │   1.05 │                 2.85 │  1450.0 │\n│   14.39 │       1.87 │   2.45 │              14.6 │ … │            5.25 │   1.02 │                 3.58 │  1290.0 │\n│   14.06 │       2.15 │   2.61 │              17.6 │ … │            5.05 │   1.06 │                 3.58 │  1295.0 │\n│   14.83 │       1.64 │   2.17 │              14.0 │ … │             5.2 │   1.08 │                 2.85 │  1045.0 │\n│   13.86 │       1.35 │   2.27 │              16.0 │ … │            7.22 │   1.01 │                 3.55 │  1045.0 │\n├─────────┴────────────┴────────┴───────────────────┴───┴─────────────────┴────────┴──────────────────────┴─────────┤\n│ 10 rows                                                                                      13 columns (8 shown) │\n└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n```\n:::\n:::\n\n\n## PyArrow\n\nNow that we have a database connection, we can run SQL or use existing Python code to retrieve our data. \n\nDuckDB and my workflow can return and Arrow object. If your use case can't and returns a pandas dataframe, you will need PyArrow to convert it. \n\n\n::: {.cell}\n\n```{.python .cell-code}\n\ndf_pyarrow = duckdb.sql('SELECT * FROM my_table').fetch_arrow_table()\n\n# If what you are using returns pandas dataframe\ndf_pyarrow_pandas = pa.Table.from_pandas(data)\n```\n:::\n\n\n## Seemless conversion to R\n\nNow the wine dataset is simple enough to work with in Python. With this size, writing a csv or parquet file is even feasible. \n\nHowever, if you have data that is 10+ million rows, that isn't going to be a sustainable solution. How do you transfer the data while reducing I/O constraints as much as possible?\n\n#### Arrow\n\nI've mentioned Arrow many times throughout this post, and will continue to reference other sources for further understanding. A high level overview is that it is a standardized memory format for data, independent of language or tooling. \n\nIn the most basic use case of transferring a Pandas dataframe to R, there is a conversion of how it was stored in memory for Pandas and a mapping of how it will be stored in memory for an R `data.frame()`. To do that requires copying the data. This is called **Serialization**. \n\nWith Arrow, that definition is constant and allows for *zero-copy* reads without serialization.\n\n#### Final Product\n\nNow this part is absolutely silly, the only piece that was missing from Danielle's article was that `py_to_r()` wasn't even needed. All I had to do was assign an r variable with the Python object with Reticulate: `df <- py$df`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntictoc::tic()\ndf_arrrow1 <- reticulate::py$df_pyarrow\ntictoc::toc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.014 sec elapsed\n```\n:::\n\n```{.r .cell-code}\ndf_arrrow1 |> \n  utils::head() |> \n  dplyr::collect()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 13\n  alcohol malic_acid   ash alcalinity_of_ash magnesium total_phenols flavanoids\n    <dbl>      <dbl> <dbl>             <dbl>     <dbl>         <dbl>      <dbl>\n1    14.2       1.71  2.43              15.6       127          2.8        3.06\n2    13.2       1.78  2.14              11.2       100          2.65       2.76\n3    13.2       2.36  2.67              18.6       101          2.8        3.24\n4    14.4       1.95  2.5               16.8       113          3.85       3.49\n5    13.2       2.59  2.87              21         118          2.8        2.69\n6    14.2       1.76  2.45              15.2       112          3.27       3.39\n# ℹ 6 more variables: nonflavanoid_phenols <dbl>, proanthocyanins <dbl>,\n#   color_intensity <dbl>, hue <dbl>, `od280/od315_of_diluted_wines` <dbl>,\n#   proline <dbl>\n```\n:::\n\n```{.r .cell-code}\n# If pandas to arrow needed\ndf_arrow2 <- reticulate::py$df_pyarrow_pandas\ndf_arrrow1 |> \n  utils::head() |> \n  dplyr::collect()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 13\n  alcohol malic_acid   ash alcalinity_of_ash magnesium total_phenols flavanoids\n    <dbl>      <dbl> <dbl>             <dbl>     <dbl>         <dbl>      <dbl>\n1    14.2       1.71  2.43              15.6       127          2.8        3.06\n2    13.2       1.78  2.14              11.2       100          2.65       2.76\n3    13.2       2.36  2.67              18.6       101          2.8        3.24\n4    14.4       1.95  2.5               16.8       113          3.85       3.49\n5    13.2       2.59  2.87              21         118          2.8        2.69\n6    14.2       1.76  2.45              15.2       112          3.27       3.39\n# ℹ 6 more variables: nonflavanoid_phenols <dbl>, proanthocyanins <dbl>,\n#   color_intensity <dbl>, hue <dbl>, `od280/od315_of_diluted_wines` <dbl>,\n#   proline <dbl>\n```\n:::\n:::\n\n\nI'm off to go work in my preferred environment... \n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}