{
  "hash": "185c62af9238beb54e0123b0fb85df8e",
  "result": {
    "markdown": "---\ntitle: \"Modeling Airports (Cont.)\"\nauthor: \"Ryan Plain\"\ndate: \"2024-06-02\"\ncategories: [Flights, R]\ndescription: \"test\"\ndraft: true\nformat: \n  html: \n    code-fold: true\n    code-summary: \"Show the code\"\n\n---\n\n\n\n## Flight Analytics\n\nIn this post, we continue our exploration of modeling passenger and baggage traffic in airports using publicly available data. To streamline our data processing, I created a simple R package [flightanalytics](https://github.com/rplain1/flightanalytics). This package helps to build dataframes from the [Planning Guidelines and Design Standards for TSA](https://iabsc.org/wp-content/uploads/2021/04/Planning-Guidelines-and-Design-Standards-for-Checked-Baggage-Inspection-Systems-V7.0.pdf) study. \n\nFor now, we will use the arrival curve and some carrier-level aggregated passenger and bag data from the TSA document. The `flightanalytics` package is used for storing the logic required to build these tables from the PDF document. By consolidating this logic into a package, we can easily reuse and extend it if we encounter more repetitive code patterns in future work. \n\nI know \"we\" is just me and my wife right now. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(nycflights13)\nlibrary(flightanalytics) # hey look thats new\nlibrary(ks) # this is new too\n\n\njune27_flights <- flights |> \n  mutate(dep_dttm = time_hour + minutes(minute)) |> \n  filter(day == 27 , month == 6)\n\n\narrival_curve <- get_pgds_arrival_curve() |> \n  clean_arrival_curve()\n\n\npax_bag_data <- get_pgds_passenger_bag_factors()\n```\n:::\n\n\n\n### Recap of Arrival curve\n\nHere's a summary of the arrival curves from the [previous post](https://www.ryanplain.com/posts/2024-06-01-flight-data/), which show the distribution using a continuous custom distribution:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(0527)\n\narrival_samples <- arrival_curve |> \n  group_by(name) |> \n  nest() |> \n  ungroup() |> \n  mutate(\n    samples = map(.x = data, ~sample(.x$minutes_prior, 1000, replace = TRUE, prob = .x$value))\n  ) |> \n  mutate(\n    d = map(samples, ~density(.x)),\n    density_x = map(d, \"x\"),\n    density_y = map(d, \"y\"),\n    dens = tibble(dens_x = map(d, \"x\"), dens_y = map(d, \"y\"))\n  ) |> \n  ungroup() \n\narrival_kde <- arrival_samples |> \n  select(name, starts_with('density')) |> \n  unnest(c(density_x, density_y)) |> \n  filter(density_x > 0) |> \n  group_by(name) |> \n  mutate(y = density_y / sum(density_y)) |>\n  select(name, minutes_prior = density_x, perc = y) |> \n  ungroup()\n\narrival_kde |> \n  ggplot(aes(minutes_prior, perc, color = name)) +\n  geom_line(linewidth = 2) + \n  labs(\n    title = 'KDE of Arrival Curve',\n    x = 'Minutes Prior',\n    y = NULL,\n    color = NULL,\n    fill = NULL,\n  ) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  scale_x_reverse() + \n  theme(legend.position = 'top')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n### What's a KDE?\n\nOne thing we touched on last time was using the Kernel Density Estimate (KDE). If you have every used `plot(density(x))`, you have used a KDE. You can learn more about it [here](https://en.wikipedia.org/wiki/Kernel_density_estimation), but to summarize it is a smoothing function to estimate the probability density function of a random variable.\n\n::: {.callout-note collapse=\"true\"}\n## Make it Simple\n\nI failed Algebra I multiple times, and I still have trauma from Greek letters in grad school. I was someone who learned math and statistics more effectively through programming. It's not for everyone (the way math is traditionally taught also isn't for everyone), but I found everything easier to learn inside a for loop. Colors help too. \n\nI'll link to Wikipedia and other sources to detail the math used, because that is important too. Just learn however is best for you, and it doesn't have to be how everyone else does it. If I add context it will be to make it as simple to grasp as possible, and I will never use the Greek alphabet.  \n:::\n\n\n### A quick example\n\nIn this example, 100 values are sampled from a normal distribution. However, due to the relatively small sample size, the resulting distribution may not precisely match the true normal distribution. Interestingly, I set my anniversary date as the random seed for reproducibility, and it unexpectedly yielded a bimodal density in the sample. The flexibility of the smoothing function is what allows us to match the unique arrival curve shapes. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate example data\nset.seed(0527)  # For reproducibility\ndata <- data.frame(value = rnorm(100, mean = 5, sd = 2))\n\n# Plot the histogram with density line\nggplot(data, aes(x = value)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 0.5, fill = \"blue\", alpha = 0.5) +\n  geom_density(color = \"red\", linewidth = 1) +\n  labs(title = \"Histogram with Density Line\",\n       x = \"Value\",\n       y = \"Density\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n### Create Base Flight Schedule\n\nAt the moment, this code is some `dplyr` mess that should be wrapped into a function to clean the flight schedule into a usable format. The main takeaway is that we have a flight schedule with the estimated passengers and bags for each flight.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairports <- airports |> \n  mutate(domestic = str_detect(tzone, 'America'),\n         domestic = replace_na(domestic, FALSE))\n\n\n\n arrival_curve_kde <- arrival_curve |> \n    group_by(name) |> \n    nest() |> \n    ungroup() |> \n    mutate(\n      samples = map(.x = data, ~sample(.x$minutes_prior, 1000, replace = TRUE, prob = .x$value))\n    ) |> \n    mutate(\n      .kde = map(.x = samples, ~ks::kde(.x)),\n    ) |> \n    mutate(\n      peak = name == 'peak_domestic_8am',\n      domestic = !str_detect(name, 'international')\n      )\n\n\n\njune_27_base <- june27_flights |> \n  left_join(planes |> select(tailnum, seats), by = c('tailnum')) |> \n  left_join(pax_bag_data, by = c('carrier')) |> \n  left_join(airports, by =c('dest' = 'faa')) |> \n  mutate(\n    domestic = replace_na(domestic, FALSE),\n    join_arr_col = case_when(\n      domestic == FALSE ~ 'international',\n      sched_dep_time <= 800 ~ 'peak_domestic_8am',\n      TRUE ~ 'off_peak_domestic'\n    ),\n    # use median values for missing airline data\n    across(c(contains('factor'), avg_num_bags ), \\(x) replace_na(x, median(x, na.rm = TRUE)))\n  ) |> \n  group_by(carrier) |> \n  mutate(seats = replace_na(seats, median(seats, na.rm = TRUE))) |> \n  ungroup() |> \n  mutate(\n    passengers = round(seats * load_factor),\n    passengers_with_bag = round(seats * check_bag_factor),\n    num_of_bags = round(passengers * avg_num_bags)\n  ) |> \n  left_join(\n    arrival_curve_kde,\n      by = c('join_arr_col' = 'name'),\n    suffix = c('_base', '_arr_curve')\n    ) |> \n    select(carrier, origin, dest, dep_dttm, passengers:num_of_bags, arr_curve = join_arr_col, .kde)\n\njune_27_base |> \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  carrier origin dest  dep_dttm            passengers passengers_with_bag\n  <chr>   <chr>  <chr> <dttm>                   <dbl>               <dbl>\n1 UA      EWR    MIA   2013-06-27 20:10:00        127                  67\n2 B6      JFK    MCO   2013-06-27 21:46:00         18                  18\n3 B6      JFK    FLL   2013-06-27 21:55:00        180                 180\n4 B6      JFK    BUF   2013-06-27 21:10:00         18                  18\n5 UA      EWR    CLE   2013-06-27 20:21:00        127                  67\n6 B6      JFK    BOS   2013-06-27 23:00:00         18                  18\n# ℹ 3 more variables: num_of_bags <dbl>, arr_curve <chr>, .kde <list>\n```\n:::\n:::\n\n\n\n# Sampling from distribution\n\nPreviously, we applied a flat factor across the 10-minute arrival curve. Now, we're adding some variance to enhance our modeling.\n\nEach flight now has one of the three different types of arrival curves associated with it. With the number of expected passengers, we want to have a value of how many minutes prior to departure they arrive. To implement this, we're utilizing `purrr` to apply the function `ks::rkde` to each row, adjusting for the number of passengers dynamically.\n\nThis approach enables us to introduce variability into our arrival curve modeling, enhancing the fidelity of our simulations and better capturing real-world scenarios.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\njune_27_kde_1 <- june_27_base |> \n  mutate(\n    arrivals = map2(.x = .kde, .y = passengers,  ~ks::rkde(.y, .x))\n  ) \n\njune_27_kde_1 |> \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 10\n  carrier origin dest  dep_dttm            passengers passengers_with_bag\n  <chr>   <chr>  <chr> <dttm>                   <dbl>               <dbl>\n1 UA      EWR    MIA   2013-06-27 20:10:00        127                  67\n2 B6      JFK    MCO   2013-06-27 21:46:00         18                  18\n3 B6      JFK    FLL   2013-06-27 21:55:00        180                 180\n4 B6      JFK    BUF   2013-06-27 21:10:00         18                  18\n5 UA      EWR    CLE   2013-06-27 20:21:00        127                  67\n6 B6      JFK    BOS   2013-06-27 23:00:00         18                  18\n# ℹ 4 more variables: num_of_bags <dbl>, arr_curve <chr>, .kde <list>,\n#   arrivals <list>\n```\n:::\n\n```{.r .cell-code}\njune_27_kde_1 |> \n  unnest(arrivals) |> \n  ggplot(aes(arrivals, fill = arr_curve)) + \n  geom_histogram(bins=50) + \n  facet_wrap(~arr_curve, ncol = 1, scales = 'free_y') +\n  scale_x_reverse() +\n  theme(\n    legend.position = 'none'\n  ) +\n  labs(\n    title = 'Sampled Arrivals from Arrival Curve',\n    subtitle = 'Note: the y axis are on different scales due to the disproportionate amount of domestic flights',\n    x = 'Minutes Prior to Departure',\n    y = 'Count'\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\njune_27_arrivals_long <- june_27_kde_1 |> \n  unnest(arrivals) |> \n  mutate(model_dttm = dep_dttm - minutes(round(arrivals))) \n  \njune_27_arrivals_long |> \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 11\n  carrier origin dest  dep_dttm            passengers passengers_with_bag\n  <chr>   <chr>  <chr> <dttm>                   <dbl>               <dbl>\n1 UA      EWR    MIA   2013-06-27 20:10:00        127                  67\n2 UA      EWR    MIA   2013-06-27 20:10:00        127                  67\n3 UA      EWR    MIA   2013-06-27 20:10:00        127                  67\n4 UA      EWR    MIA   2013-06-27 20:10:00        127                  67\n5 UA      EWR    MIA   2013-06-27 20:10:00        127                  67\n6 UA      EWR    MIA   2013-06-27 20:10:00        127                  67\n# ℹ 5 more variables: num_of_bags <dbl>, arr_curve <chr>, .kde <list>,\n#   arrivals <dbl>, model_dttm <dttm>\n```\n:::\n\n```{.r .cell-code}\njune_27_arrivals_long |> \n  count(origin, model_dttm) |> \n  ggplot(aes(model_dttm, n, color = origin)) + \n  geom_line() + \n  facet_wrap(~origin, ncol = 1) +\n  theme(\n    legend.position = 'none'\n  ) +\n  labs(\n    title = 'Passenger Arrivals Throughout the Day',\n    x = 'Minutes Prior to Departure',\n    y = 'Count'\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n:::\n\n\n### Journey to 10k\n\nHow many simulations do you need? I often see \"this analysis was based of 10,000\" simulations, but if your underlying function doesn't actually match the real world -- then there isn't a number that will monte carlo your way out of it. The answer is, as always, it depends. \n\nWe are simulating one metric right now, maybe 1,000 is enough for this. Also what is the goal or intended outcome the model serves? If it is extreme tail end outcomes, 1,000 might not be enough. 100,000 might not be enough. The larger number of simulations will be important as we incorporate other metrics like load and bag factors to it. \n\n#### Steps\n\n1. Take the flight schedule and create a number of simulations that you want to do\n2. Replicate each flight for the number of sims, this example uses `tidyr::unnest()` of a list column\n3. Apply the sampling function for each passenger\n4. Unnest again, and now you have the number of simulations and number of passengers in each row\n\n\nBut wait... \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nSIMS <- 100\n\njune_27_kde_100 <- june_27_base |> \n  mutate(sim_number = list(1:SIMS)) |> \n  unnest(sim_number) |> \n  mutate(\n    arrivals = map2(.x = .kde, .y = passengers,  ~ks::rkde(.y, .x))\n  ) |> \n  unnest(arrivals)\n\n\npaste(\"Number of rows:\", nrow(june_27_kde_100))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Number of rows: 11615900\"\n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}