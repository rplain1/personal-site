[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nothing Plain About It",
    "section": "",
    "text": "Reactable Demo\n\n\n\n\n\n\n\nReactable\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\nAug 29, 2023\n\n\nRyan Plain\n\n\n\n\n\n\n  \n\n\n\n\nArrow, Python, & R\n\n\n\n\n\n\n\nArrow\n\n\nPython\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 19, 2023\n\n\nRyan Plain\n\n\n\n\n\n\n  \n\n\n\n\nBlank Canvas\n\n\n\n\n\n\n\n\n\n\n\n\nJun 18, 2023\n\n\nRyan Plain\n\n\n\n\n\n\n  \n\n\n\n\nFantasy Football Data Wrangling for Keepers\n\n\n\n\n\n\n\nFantasy Football\n\n\nAnalysis\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2021\n\n\nRyan Plain\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Blog Reconstruction",
    "section": "",
    "text": "Hi, welcome to my site!\nI recently finished grad school, moved states, and got married. Life has been hectic and not allowed time for public work. I’m hoping to be able to tackle some public projects moving forward.\nI’m particularly excited about new developments with the Apache Arrow project, and how to bridge the gap with R and Python users. I have ADHD, which means I think in a non-linear and sporadic fashion. R will always be my true love for data analysis, with non-standard evaluation and emphasis by the Posit team on designing their API’s to be a fluid conversation with data.\nI have love for python too. Python was the first language I picked up. It taught me the beauty of understanding another way of thinking (something I again rediscovered learning about octopuses). I never excelled in math in the traditional school setting, but being able to define functions and interactively test different inputs really connected me in a way that greek letters and chalkboard never could. This is especially true for linear algebra. I don’t know that I would have any understanding if it wasn’t for numpy.\nThis is why I’m excited about polars. I love numpy and the optimization and syntax, however, it did not hold up well as a pandas backend as data grew more complex. Polars offers a syntax that requires less cognitive overhead, and the backed power of arrow and rust.\nAt work, I use these tools to be able to work in the R ecosystem for data exploration, which works for me. Additionally, I’m able to leverage arrow to convert back to python for our team’s development and machine learning environment.\nMy first (new) post will be detailing what that workflow looks like, and how easy it is to work within Quarto.\nIn the meantime, I left one (1) silly post about fantasy football. Mainly because I run that script once a year and still need it. Plus it’s always neat to be able to look back and see how far you’ve come."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a data analyst living in Colorado Springs, currently working in product analytics. Previously I worked simulating passenger and and bag traffic through airport facilities.\nMy passion is in making processes more efficient. Whether that is ETL pipelines to expose better analytics tables, visualizations that save time on investigating or filtering, or automating tedious steps in the analysis workflow. I’m a proponent of working with what tool and environment works best for you, and enjoy designing solutions to be inclusive for everyone.\nIn my free time I love exploring the outdoors, climbing, yoga, and spending time with my wife, dogs, and evil cat."
  },
  {
    "objectID": "posts/2021-03-21-complicated-keeper-data-manipulation/complicated-keeper-data-manipulation.html",
    "href": "posts/2021-03-21-complicated-keeper-data-manipulation/complicated-keeper-data-manipulation.html",
    "title": "Complicated Keeper Data Manipulation",
    "section": "",
    "text": "My previous post dove in on sample analysis of our fantasy football league utilizing the API from Sleeper. Since then, I have discovered an amazing package {ffscrapr} on CRAN, developed by Tan. This package does everything for you to get data from Sleeper into easy to work with data frames."
  },
  {
    "objectID": "posts/2021-03-21-complicated-keeper-data-manipulation/complicated-keeper-data-manipulation.html#the-goal",
    "href": "posts/2021-03-21-complicated-keeper-data-manipulation/complicated-keeper-data-manipulation.html#the-goal",
    "title": "Complicated Keeper Data Manipulation",
    "section": "The Goal",
    "text": "The Goal\n\n\n\n\n\nEach year we draft players for the upcoming season, which is typically referred to as redraft format. A couple years ago we began a keeper format where we can keep a player from the previous year.\nThere are several ways to implement a keeper format, our rules are as follows:\n\nKeep 1 player, that player can not be kept consecutive years\n\nThe kept player will be kept at the round they were drafted in with a single round penalty (i.e. if you drafted a player in round 10, you would keep them in round 9 the following year)\n\nIf you trade a player, the new team gets the rights to keep that player\n\nThe player must remain on the roster at least until the week before their respective bye week\n\nAs you can imagine, this is a nightmare to track in a spreadsheet as a commissioner."
  },
  {
    "objectID": "posts/2021-03-21-complicated-keeper-data-manipulation/complicated-keeper-data-manipulation.html#the-solution",
    "href": "posts/2021-03-21-complicated-keeper-data-manipulation/complicated-keeper-data-manipulation.html#the-solution",
    "title": "Complicated Keeper Data Manipulation",
    "section": "The Solution",
    "text": "The Solution\nOnly a few packages needed (if you count {tidyverse} as a few that is) to begin the analysis.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors"
  },
  {
    "objectID": "posts/2021-03-21-complicated-keeper-data-manipulation/complicated-keeper-data-manipulation.html#ffscrapr",
    "href": "posts/2021-03-21-complicated-keeper-data-manipulation/complicated-keeper-data-manipulation.html#ffscrapr",
    "title": "Complicated Keeper Data Manipulation",
    "section": "ffscrapr",
    "text": "ffscrapr\nTan has well documented how the package works through the {ffscraper} website. I won’t go into too much detail, as the API is fairly simple to understand from the function names alone. Basically, create a league object and get the draft picks and transactions for it.\nThe league I will be focusing on is a leauge is called The Hot Boyz… Hopefully Dallas Cowboys fans understand!\n\nmy_leagues <- ffscrapr::sleeper_userleagues(\"rplain\", 2020)\n\nleague_id <- my_leagues %>% \n  filter(league_name == 'The Hot Boyz') %>% \n  pull(league_id)\n\nmy_league <- ffscrapr::ff_connect(platform = 'sleeper', \n                                  season = 2020, \n                                  league_id = league_id)\n\ntransactions <- ff_transactions(my_league)\n\ndraft_picks <- ff_draft(my_league) \n\n\nBelow is what the draft board looked like following the draft.\n\ndraft_picks %>% \n  select(round, pick, franchise_name, player_name, pos, team) %>% \n   mutate(player_name = ifelse(is.na(player_name), paste(team, \" Def\"), player_name)) %>% \n  pivot_wider(\n    id_cols = round,\n    names_from = franchise_name,\n    values_from = player_name\n  ) %>% \n  `colnames<-`(c(\"Round\",1:10)) %>% \n  gt::gt()\n\n\n\n\n\n  \n  \n    \n      Round\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      10\n    \n  \n  \n    1\nChristian McCaffrey\nEzekiel Elliott\nSaquon Barkley\nMichael Thomas\nDalvin Cook\nAlvin Kamara\nLe'Veon Bell\nJoe Mixon\nMiles Sanders\nDavante Adams\n    2\nChris Godwin\nJosh Jacobs\nDeAndre Hopkins\nTravis Kelce\nTyreek Hill\nPatrick Mahomes\nNick Chubb\nChris Carson\nJulio Jones\nClyde Edwards-Helaire\n    3\nJames Conner\nMike Evans\nAustin Ekeler\nDavid Johnson\nGeorge Kittle\nAdam Thielen\nTodd Gurley\nKenny Golladay\nJonathan Taylor\nMark Andrews\n    4\nRobert Woods\nJuJu Smith-Schuster\nAmari Cooper\nAaron Jones\nMelvin Gordon\nCalvin Ridley\nRaheem Mostert\nAllen Robinson\nOdell Beckham\nDerrick Henry\n    5\nMark Ingram\nA.J. Brown\nKareem Hunt\nCooper Kupp\nD.J. Chark\nZach Ertz\nStefon Diggs\nKeenan Allen\nD.J. Moore\nTerry McLaurin\n    6\nMichael Gallup\nMarquise Brown\nDevin Singletary\nRussell Wilson\nDak Prescott\nKenyan Drake\nTyler Lockett\nT.Y. Hilton\nCam Akers\nDeshaun Watson\n    7\nAntonio Gibson\nJ.K. Dobbins\nDarren Waller\nDavid Montgomery\nLeonard Fournette\nDeVante Parker\nWill Fuller\nMarlon Mack\nZack Moss\nTyler Boyd\n    8\nBrandin Cooks\nRonald Jones\nA.J. Green\nScott Miller\nSF  Def\nJames White\nRob Gronkowski\nEvan Engram\nKyler Murray\nJulian Edelman\n    9\nLamar Jackson\nCeeDee Lamb\nJerry Jeudy\nJordan Howard\nDiontae Johnson\nHenry Ruggs\nTyler Higbee\nD'Andre Swift\nDeebo Samuel\nJarvis Landry\n    10\nNoah Fant\nJared Cook\nMatt Ryan\nHayden Hurst\nEmmanuel Sanders\nAustin Hooper\nCam Newton\nMarvin Jones\nTarik Cohen\nMatt Breida\n    11\nPIT  Def\nTom Brady\nJohn Brown\nPhillip Lindsay\nChristian Kirk\nBAL  Def\nNE  Def\nChris Thompson\nChase Edmonds\nJamison Crowder\n    12\nTony Pollard\nKerryon Johnson\nJustin Jefferson\nBUF  Def\nTevin Coleman\nSony Michel\nSterling Shepard\nLatavius Murray\nDamien Harris\nAaron Rodgers\n    13\nAnthony Miller\nMecole Hardman\nBlake Jarwin\nAlexander Mattison\nDarius Slayton\nJoe Burrow\nCourtland Sutton\nJosh Allen\nPreston Williams\nHunter Henry\n    14\nGolden Tate\nO.J. Howard\nJosh Gordon\nAllen Lazard\nT.J. Hockenson\nDeSean Jackson\nLarry Fitzgerald\nBryan Edwards\nChristopher Herndon\nTEN  Def\n    15\nDevonta Freeman\nLAC  Def\nMIN  Def\nRyquell Armstead\nDK Metcalf\nA.J. Dillon\nSammy Watkins\nIND  Def\nParris Campbell\nMike Gesicki\n  \n  \n  \n\n\n\n\nThis was the initial draft board. My team was the 9th slot. I traded away Julio Jones and cut Odell Beckham Jr. after he went to Injured Reserve. There needs to be a logic to represent these moves, as they are no longer eligible to keep.\nIn addition to structuring the rules, I would like to:\n\nProvide color the names by each player’s position, as is typical on most fantasy football draft boards.\nAllow multiple players to occupy a draft slot. In the case of a traded player, there can be overlap on eligible keepers for one team in a particular round .\n\nThese can not be done with a pivot table (at least not without hardcoding elements). The final output will need to be in a tidy format to allow usage of the grammar of graphics in {ggplot2}.\n\nIneligible Keepers\nTo start with, create a list of the players kept from 2019 in 2020. The players are no longer eligible and need to be filtered out.\nThe NFL and fantasy football is played weekly. Using the {lubridate}, create week 1 of the NFL season from the timestamp field in the transactions data frame.\nTo get the players that were dropped early in advance of their bye week:\n\nFilter for transactions that successfully dropped players\nAdd in each teams bye week\nGet the earliest drop (each player can be added/dropped multiple times throughout the season)\n\nSubset as a list of unique names\n\n\nkept_players <- c(\n  'Lamar Jackson',\n  'Josh Jacobs',\n  'Austin Ekeler',\n  'Aaron Jones',\n  'DK Metcalf',\n  'Kenyan Drake',\n  'Courtland Sutton',\n  'Josh Allen',\n  'D.J. Moore',\n  'Derrick Henry'\n)  \n\ntransactions <- transactions %>% \n  mutate(week = lubridate::week(timestamp) - 36)\n\n\ndropped_players <- transactions %>% \n  filter(type_desc == 'dropped') %>% \n  filter(type != 'waiver_failed') %>% \n  mutate(\n    bye_weeks = case_when(\n      team %in% c(\"PIT\", \"TEN\") ~ 4,\n      team %in% c(\"DEN\", \"DET\", \"GB\", \"NE\") ~ 5,\n      team %in% c(\"LV\", \"LAC\", \"NO\", \"SEA\") ~ 6,\n      team %in% c(\"BAL\", \"IND\", \"MIA\", \"MIN\") ~ 7,\n      team %in% c(\"ARI\", \"HOU\", \"JAX\", \"WAS\") ~ 8,\n      team %in% c(\"CIN\", \"CLE\", \"LAR\", \"PHI\") ~ 9,\n      team %in% c(\"ATL\", \"DAL\", \"KC\", \"NYJ\") ~ 10,\n      team %in% c(\"BUF\", \"CHI\", \"NYG\", \"SF\") ~ 11,\n      team %in% c(\"CAR\", \"TB\") ~ 13\n    )\n  ) %>% \n  group_by(player_name, player_id) %>% \n  arrange(timestamp, player_id) %>% \n  mutate(rn = row_number()) %>% \n  filter(rn == 1) %>% \n  filter(week < bye_weeks - 1) %>% \n  #filter(franchise_id == 1) %>% print(n= 32)\n  pull(player_name) %>% \n  unique()\n\n\n\nTraded Players\n{ffscrapr} does so much of the leg work for you. In the transactions of the trade, a field trade_partner is already included which contains the ID of who the trade went to.\nAgain, follow a similar logic to most recent occurrence of the traded player. For example, Michael Gallup was traded 3 times in our league. He needs to be placed on the final team he ended up on.\nA separate table franchises was created to join the franchise_name to the output.\nFinally, I created a list of the names in our league. If you didn’t see my previous work, you might notice the 9th spot did not turn out so well.\n\nfranchises <- draft_picks %>% \n  count(franchise_id, franchise_name, pick) %>% \n  select(-n) \n\ntrades <- transactions %>% \n  filter(type == 'trade') %>% \n  group_by(player_name) %>% \n  arrange(timestamp) %>% \n  mutate(rn = row_number()) %>% \n  filter(rn == max(rn)) %>% \n  select(franchise_id, franchise_name, player_name, trade_partner) %>%\n  mutate(trade_partner = as.numeric(trade_partner)) %>% \n  left_join(\n    franchises, by = c(\"trade_partner\"=\"franchise_id\"), suffix = c(\"\",\"_trade\")\n  ) \n\nusers <- c(\n  'CHAMP',\n  'Wayne',\n  'Jacob',\n  'Tony',\n  'Ben',\n  'Clayton',\n  'Zach',\n  'Mitch',\n  'Last Place',\n  'Connor'\n)"
  },
  {
    "objectID": "posts/2021-03-21-complicated-keeper-data-manipulation/complicated-keeper-data-manipulation.html#the-plot",
    "href": "posts/2021-03-21-complicated-keeper-data-manipulation/complicated-keeper-data-manipulation.html#the-plot",
    "title": "Complicated Keeper Data Manipulation",
    "section": "The Plot",
    "text": "The Plot\n\ndraft_picks %>% \n  filter(round != 1) %>% \n  mutate(round = round - 1) %>% \n  mutate(url = glue::glue(\n    \"https://sleepercdn.com/content/nfl/players/thumb/{player_id}.jpg\"\n  )) %>% \n  bind_rows(\n    tibble(\n      round = rep(0, 10), \n      player_name = users,\n      pick = 1:10\n      )\n    ) %>% \n  filter(!player_name %in% dropped_players & !player_name %in% kept_players) %>%\n  left_join(\n    trades, \n    by = c(\"franchise_name\", \"player_name\"),\n    suffix = c(\"\", \"_trade\")\n  ) %>% \n  mutate(pick = ifelse(\n    !is.na(pick_trade) & round != 0,\n    pick_trade, \n    pick\n    )) %>% \n  group_by(round, pick) %>% \n  mutate(hjust = n(),\n         hjust_n = row_number()) %>% \n  ungroup() %>% \n  mutate(player_name = case_when(\n    player_name == 'Clyde Edwards-Helaire'~'C. Edwards-Helaire',\n    TRUE ~ player_name\n  )) %>% \n  ggplot(aes(pick, round)) +\n  geom_point(alpha = 0) +\n  geom_label(\n    aes(label = player_name, fill = pos), \n    show.legend = F, \n    data = . %>% filter(round > 0, hjust > 1, hjust_n == 1),\n    vjust = 1,\n    size = 5\n  ) +\n  geom_label(\n    aes(label = player_name, fill = pos),\n    size = 5, \n    show.legend = F, \n    data = . %>% filter(round > 0, hjust > 1, hjust_n == 2),\n    vjust = -0.1\n  ) +\n  geom_label(\n    aes(label = player_name, fill = pos), \n    size = 5, \n    show.legend = F, \n    data = . %>% filter(round > 0, hjust == 1)\n    ) +\n  geom_text(\n    aes(label = player_name),\n    data = . %>% \n      filter(round == 0),\n    size = 7,\n    color = \"#FFFFFF\"\n  ) +\n  scale_y_reverse(breaks = c(1:15)) +\n  theme_minimal() +\n  labs(\n    title = \"Keepers 2021\",\n    x = NULL,\n    y = NULL\n  ) +\n  theme(\n    panel.grid = element_blank(),\n    axis.text.x = element_blank(),\n    axis.text.y = element_text(color=\"#FFFFFF\", size = 18),\n    plot.title = element_text(size = 30, face = \"bold\", hjust = 0.5, color = \"#FFFFFF\"),\n    plot.background = element_rect(fill = \"#494f5c\"),\n  ) +\n  geom_hline(yintercept = 0.5) +\n  geom_hline(yintercept = seq(1.5, 13.5, 1), alpha = 0.5) +\n  scale_fill_manual(\n    values =  c(\"#d65858\",\"#00ba5d\",\"#ff7c43\", \"#58ffff\")\n  )\n\n\n\n\n\n\nI’ve included the code on how I created the plot, however I’ve cut a corner by not having the code evaluated at runtime, and the static image is passed through.\nI still have a lot to learn with {ggplot2}, especially when it comes to rendering the graphic in dimensions needed. Overall it was a neat problem thinking about how to represent the draftboard.\nThat wraps up this project. Thanks again to Tan for the awesome package!"
  },
  {
    "objectID": "posts/2021-03-21-complicated-keeper-data-manipulation/index.html",
    "href": "posts/2021-03-21-complicated-keeper-data-manipulation/index.html",
    "title": "Fantasy Football Data Wrangling for Keepers",
    "section": "",
    "text": "Working with {ffscrapr}\nMy previous post dove in on sample analysis of our fantasy football league utilizing the API from Sleeper. Since then, I have discovered an amazing package {ffscrapr} on CRAN, developed by Tan. This package does everything for you to get data from Sleeper into easy to work with data frames."
  },
  {
    "objectID": "posts/2021-03-21-complicated-keeper-data-manipulation/index.html#the-goal",
    "href": "posts/2021-03-21-complicated-keeper-data-manipulation/index.html#the-goal",
    "title": "Fantasy Football Data Wrangling for Keepers",
    "section": "The Goal",
    "text": "The Goal\n\n\n\n\n\nEach year we draft players for the upcoming season, which is typically referred to as redraft format. A couple years ago we began a keeper format where we can keep a player from the previous year.\nThere are several ways to implement a keeper format, our rules are as follows:\n\nKeep 1 player, that player can not be kept consecutive years\n\nThe kept player will be kept at the round they were drafted in with a single round penalty (i.e. if you drafted a player in round 10, you would keep them in round 9 the following year)\n\nIf you trade a player, the new team gets the rights to keep that player\n\nThe player must remain on the roster at least until the week before their respective bye week\n\nAs you can imagine, this is a nightmare to track in a spreadsheet as a commissioner."
  },
  {
    "objectID": "posts/2021-03-21-complicated-keeper-data-manipulation/index.html#the-solution",
    "href": "posts/2021-03-21-complicated-keeper-data-manipulation/index.html#the-solution",
    "title": "Fantasy Football Data Wrangling for Keepers",
    "section": "The Solution",
    "text": "The Solution\nOnly a few packages needed (if you count {tidyverse} as a few that is) to begin the analysis.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors"
  },
  {
    "objectID": "posts/2021-03-21-complicated-keeper-data-manipulation/index.html#ffscrapr",
    "href": "posts/2021-03-21-complicated-keeper-data-manipulation/index.html#ffscrapr",
    "title": "Fantasy Football Data Wrangling for Keepers",
    "section": "ffscrapr",
    "text": "ffscrapr\nTan has well documented how the package works through the {ffscraper} website. I won’t go into too much detail, as the API is fairly simple to understand from the function names alone. Basically, create a league object and get the draft picks and transactions for it.\nThe league I will be focusing on is a leauge is called The Hot Boyz… Hopefully Dallas Cowboys fans understand!\n\nmy_leagues <- ffscrapr::sleeper_userleagues(\"rplain\", 2020)\n\nleague_id <- my_leagues %>% \n  filter(league_name == 'The Hot Boyz') %>% \n  pull(league_id)\n\nmy_league <- ffscrapr::ff_connect(platform = 'sleeper', \n                                  season = 2020, \n                                  league_id = league_id)\n\ntransactions <- ff_transactions(my_league)\n\ndraft_picks <- ff_draft(my_league) \n\n\nBelow is what the draft board looked like following the draft.\n\ndraft_picks %>% \n  select(round, pick, franchise_name, player_name, pos, team) %>% \n   mutate(player_name = ifelse(is.na(player_name), paste(team, \" Def\"), player_name)) %>% \n  pivot_wider(\n    id_cols = round,\n    names_from = franchise_name,\n    values_from = player_name\n  ) %>% \n  `colnames<-`(c(\"Round\",1:10)) %>% \n  gt::gt()\n\n\n\n\n\n  \n  \n    \n      Round\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      10\n    \n  \n  \n    1\nChristian McCaffrey\nEzekiel Elliott\nSaquon Barkley\nMichael Thomas\nDalvin Cook\nAlvin Kamara\nLe'Veon Bell\nJoe Mixon\nMiles Sanders\nDavante Adams\n    2\nChris Godwin\nJosh Jacobs\nDeAndre Hopkins\nTravis Kelce\nTyreek Hill\nPatrick Mahomes\nNick Chubb\nChris Carson\nJulio Jones\nClyde Edwards-Helaire\n    3\nJames Conner\nMike Evans\nAustin Ekeler\nDavid Johnson\nGeorge Kittle\nAdam Thielen\nTodd Gurley\nKenny Golladay\nJonathan Taylor\nMark Andrews\n    4\nRobert Woods\nJuJu Smith-Schuster\nAmari Cooper\nAaron Jones\nMelvin Gordon\nCalvin Ridley\nRaheem Mostert\nAllen Robinson\nOdell Beckham\nDerrick Henry\n    5\nMark Ingram\nA.J. Brown\nKareem Hunt\nCooper Kupp\nD.J. Chark\nZach Ertz\nStefon Diggs\nKeenan Allen\nD.J. Moore\nTerry McLaurin\n    6\nMichael Gallup\nMarquise Brown\nDevin Singletary\nRussell Wilson\nDak Prescott\nKenyan Drake\nTyler Lockett\nT.Y. Hilton\nCam Akers\nDeshaun Watson\n    7\nAntonio Gibson\nJ.K. Dobbins\nDarren Waller\nDavid Montgomery\nLeonard Fournette\nDeVante Parker\nWill Fuller\nMarlon Mack\nZack Moss\nTyler Boyd\n    8\nBrandin Cooks\nRonald Jones\nA.J. Green\nScott Miller\nSF  Def\nJames White\nRob Gronkowski\nEvan Engram\nKyler Murray\nJulian Edelman\n    9\nLamar Jackson\nCeeDee Lamb\nJerry Jeudy\nJordan Howard\nDiontae Johnson\nHenry Ruggs\nTyler Higbee\nD'Andre Swift\nDeebo Samuel\nJarvis Landry\n    10\nNoah Fant\nJared Cook\nMatt Ryan\nHayden Hurst\nEmmanuel Sanders\nAustin Hooper\nCam Newton\nMarvin Jones\nTarik Cohen\nMatt Breida\n    11\nPIT  Def\nTom Brady\nJohn Brown\nPhillip Lindsay\nChristian Kirk\nBAL  Def\nNE  Def\nChris Thompson\nChase Edmonds\nJamison Crowder\n    12\nTony Pollard\nKerryon Johnson\nJustin Jefferson\nBUF  Def\nTevin Coleman\nSony Michel\nSterling Shepard\nLatavius Murray\nDamien Harris\nAaron Rodgers\n    13\nAnthony Miller\nMecole Hardman\nBlake Jarwin\nAlexander Mattison\nDarius Slayton\nJoe Burrow\nCourtland Sutton\nJosh Allen\nPreston Williams\nHunter Henry\n    14\nGolden Tate\nO.J. Howard\nJosh Gordon\nAllen Lazard\nT.J. Hockenson\nDeSean Jackson\nLarry Fitzgerald\nBryan Edwards\nChristopher Herndon\nTEN  Def\n    15\nDevonta Freeman\nLAC  Def\nMIN  Def\nRyquell Armstead\nDK Metcalf\nA.J. Dillon\nSammy Watkins\nIND  Def\nParris Campbell\nMike Gesicki\n  \n  \n  \n\n\n\n\nThis was the initial draft board. My team was the 9th slot. I traded away Julio Jones and cut Odell Beckham Jr. after he went to Injured Reserve. There needs to be a logic to represent these moves, as they are no longer eligible to keep.\nIn addition to structuring the rules, I would like to:\n\nProvide color the names by each player’s position, as is typical on most fantasy football draft boards.\nAllow multiple players to occupy a draft slot. In the case of a traded player, there can be overlap on eligible keepers for one team in a particular round .\n\nThese can not be done with a pivot table (at least not without hardcoding elements). The final output will need to be in a tidy format to allow usage of the grammar of graphics in {ggplot2}.\n\nIneligible Keepers\nTo start with, create a list of the players kept from 2019 in 2020. The players are no longer eligible and need to be filtered out.\nThe NFL and fantasy football is played weekly. Using the {lubridate}, create week 1 of the NFL season from the timestamp field in the transactions data frame.\nTo get the players that were dropped early in advance of their bye week:\n\nFilter for transactions that successfully dropped players\nAdd in each teams bye week\nGet the earliest drop (each player can be added/dropped multiple times throughout the season)\n\nSubset as a list of unique names\n\n\nkept_players <- c(\n  'Lamar Jackson',\n  'Josh Jacobs',\n  'Austin Ekeler',\n  'Aaron Jones',\n  'DK Metcalf',\n  'Kenyan Drake',\n  'Courtland Sutton',\n  'Josh Allen',\n  'D.J. Moore',\n  'Derrick Henry'\n)  \n\ntransactions <- transactions %>% \n  mutate(week = lubridate::week(timestamp) - 36)\n\n\ndropped_players <- transactions %>% \n  filter(type_desc == 'dropped') %>% \n  filter(type != 'waiver_failed') %>% \n  mutate(\n    bye_weeks = case_when(\n      team %in% c(\"PIT\", \"TEN\") ~ 4,\n      team %in% c(\"DEN\", \"DET\", \"GB\", \"NE\") ~ 5,\n      team %in% c(\"LV\", \"LAC\", \"NO\", \"SEA\") ~ 6,\n      team %in% c(\"BAL\", \"IND\", \"MIA\", \"MIN\") ~ 7,\n      team %in% c(\"ARI\", \"HOU\", \"JAX\", \"WAS\") ~ 8,\n      team %in% c(\"CIN\", \"CLE\", \"LAR\", \"PHI\") ~ 9,\n      team %in% c(\"ATL\", \"DAL\", \"KC\", \"NYJ\") ~ 10,\n      team %in% c(\"BUF\", \"CHI\", \"NYG\", \"SF\") ~ 11,\n      team %in% c(\"CAR\", \"TB\") ~ 13\n    )\n  ) %>% \n  group_by(player_name, player_id) %>% \n  arrange(timestamp, player_id) %>% \n  mutate(rn = row_number()) %>% \n  filter(rn == 1) %>% \n  filter(week < bye_weeks - 1) %>% \n  #filter(franchise_id == 1) %>% print(n= 32)\n  pull(player_name) %>% \n  unique()\n\n\n\nTraded Players\n{ffscrapr} does so much of the leg work for you. In the transactions of the trade, a field trade_partner is already included which contains the ID of who the trade went to.\nAgain, follow a similar logic to most recent occurrence of the traded player. For example, Michael Gallup was traded 3 times in our league. He needs to be placed on the final team he ended up on.\nA separate table franchises was created to join the franchise_name to the output.\nFinally, I created a list of the names in our league. If you didn’t see my previous work, you might notice the 9th spot did not turn out so well.\n\nfranchises <- draft_picks %>% \n  count(franchise_id, franchise_name, pick) %>% \n  select(-n) \n\ntrades <- transactions %>% \n  filter(type == 'trade') %>% \n  group_by(player_name) %>% \n  arrange(timestamp) %>% \n  mutate(rn = row_number()) %>% \n  filter(rn == max(rn)) %>% \n  select(franchise_id, franchise_name, player_name, trade_partner) %>%\n  mutate(trade_partner = as.numeric(trade_partner)) %>% \n  left_join(\n    franchises, by = c(\"trade_partner\"=\"franchise_id\"), suffix = c(\"\",\"_trade\")\n  ) \n\nusers <- c(\n  'CHAMP',\n  'Wayne',\n  'Jacob',\n  'Tony',\n  'Ben',\n  'Clayton',\n  'Zach',\n  'Mitch',\n  'Last Place',\n  'Connor'\n)"
  },
  {
    "objectID": "posts/2021-03-21-complicated-keeper-data-manipulation/index.html#the-plot",
    "href": "posts/2021-03-21-complicated-keeper-data-manipulation/index.html#the-plot",
    "title": "Fantasy Football Data Wrangling for Keepers",
    "section": "The Plot",
    "text": "The Plot\n\ndraft_picks %>% \n  filter(round != 1) %>% \n  mutate(round = round - 1) %>% \n  mutate(url = glue::glue(\n    \"https://sleepercdn.com/content/nfl/players/thumb/{player_id}.jpg\"\n  )) %>% \n  bind_rows(\n    tibble(\n      round = rep(0, 10), \n      player_name = users,\n      pick = 1:10\n      )\n    ) %>% \n  filter(!player_name %in% dropped_players & !player_name %in% kept_players) %>%\n  left_join(\n    trades, \n    by = c(\"franchise_name\", \"player_name\"),\n    suffix = c(\"\", \"_trade\")\n  ) %>% \n  mutate(pick = ifelse(\n    !is.na(pick_trade) & round != 0,\n    pick_trade, \n    pick\n    )) %>% \n  group_by(round, pick) %>% \n  mutate(hjust = n(),\n         hjust_n = row_number()) %>% \n  ungroup() %>% \n  mutate(player_name = case_when(\n    player_name == 'Clyde Edwards-Helaire'~'C. Edwards-Helaire',\n    TRUE ~ player_name\n  )) %>% \n  ggplot(aes(pick, round)) +\n  geom_point(alpha = 0) +\n  geom_label(\n    aes(label = player_name, fill = pos), \n    show.legend = F, \n    data = . %>% filter(round > 0, hjust > 1, hjust_n == 1),\n    vjust = 1,\n    size = 5\n  ) +\n  geom_label(\n    aes(label = player_name, fill = pos),\n    size = 5, \n    show.legend = F, \n    data = . %>% filter(round > 0, hjust > 1, hjust_n == 2),\n    vjust = -0.1\n  ) +\n  geom_label(\n    aes(label = player_name, fill = pos), \n    size = 5, \n    show.legend = F, \n    data = . %>% filter(round > 0, hjust == 1)\n    ) +\n  geom_text(\n    aes(label = player_name),\n    data = . %>% \n      filter(round == 0),\n    size = 7,\n    color = \"#FFFFFF\"\n  ) +\n  scale_y_reverse(breaks = c(1:15)) +\n  theme_minimal() +\n  labs(\n    title = \"Keepers 2021\",\n    x = NULL,\n    y = NULL\n  ) +\n  theme(\n    panel.grid = element_blank(),\n    axis.text.x = element_blank(),\n    axis.text.y = element_text(color=\"#FFFFFF\", size = 18),\n    plot.title = element_text(size = 30, face = \"bold\", hjust = 0.5, color = \"#FFFFFF\"),\n    plot.background = element_rect(fill = \"#494f5c\"),\n  ) +\n  geom_hline(yintercept = 0.5) +\n  geom_hline(yintercept = seq(1.5, 13.5, 1), alpha = 0.5) +\n  scale_fill_manual(\n    values =  c(\"#d65858\",\"#00ba5d\",\"#ff7c43\", \"#58ffff\")\n  )\n\n\n\n\n\n\nI’ve included the code on how I created the plot, however I’ve cut a corner by not having the code evaluated at runtime, and the static image is passed through.\nI still have a lot to learn with {ggplot2}, especially when it comes to rendering the graphic in dimensions needed. Overall it was a neat problem thinking about how to represent the draftboard.\nThat wraps up this project. Thanks again to Tan for the awesome package!"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nClover | Data Analyst\nSouthwest Airlines | Data Analyst"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nGeorgia Institute of Technology | Atlanta, GA\nM.S. in Analytics\nThe University of North Texas | Denton, TX\nB.B.A. in Business Analytics"
  },
  {
    "objectID": "posts/in-progress/index.html",
    "href": "posts/in-progress/index.html",
    "title": "Untitled",
    "section": "",
    "text": "What is the reasoning behind this post? I love what I do, and can get an abundance of energy from projects that I’m working on. That being said, it’s incredibly frustrating using a specific tool, when I would enjoy and work faster in another tool.\n\n\nNothing will earn an auto-mute from me on Twitter faster than seeing a Python vs R debate. They are both fantastic tools, and each have their own strengths and weaknesses. What I find most important is to focus on how they can present themselves to a particular user. A feature I see as beneficial from R could be detrimental to another user, for a myriad of reasons.\nI support that setting up infrastructure which enables data professionals to use their tool of choice will help flourish the flow of ideas and analysis. Especially early on in the data exploration phase."
  },
  {
    "objectID": "posts/in-progress/index.html#setup",
    "href": "posts/in-progress/index.html#setup",
    "title": "Untitled",
    "section": "Setup",
    "text": "Setup\n\nDuckDB\nDuckDB is awesome. Check it out.\nAgain, this is outside the scope of this post. There is already an extensive amount of coverage on how the DB works, what it’s best for, and examples of how to use it. I mainly chose this because of it’s integration into the Apache Arrow ecosystem.\nThere are many different interfaces to install DuckDB found here: DuckDB Install.\n\n\nReticulate Config\nUsing Reticulate, we can integrate Python and R. At work, I created an R package that would allow me to use our established pipelines in python and analyze the data in R with Reticulate.\nThe intended user is already someone that is familiar with R (after all what is the point of all of this if you don’t already have {dplyr} installed?!).\n\nif(!require('reticulate')) install.packages('reticulate') \nif(!require('arrow')) install.packages('arrow') \nif(!require('tictoc')) install.packages('tictoc') # only needed for benchmark\n\nif (!reticulate::virtualenv_exists(\"demo_env\")) {\n  reticulate::virtualenv_create(\n    'demo_env'\n    , packages = c('duckdb'\n                   , 'pandas==2.0'\n                   , 'polars'\n                   , 'pyarrow'\n                   , 'scikit-learn'\n                   )\n    )\n}\n\nreticulate::use_virtualenv('demo_env')"
  },
  {
    "objectID": "posts/in-progress/index.html#python-db-connect",
    "href": "posts/in-progress/index.html#python-db-connect",
    "title": "Untitled",
    "section": "Python DB Connect",
    "text": "Python DB Connect\n\nimport duckdb \nimport pandas as pd\nimport polars as pl\nimport pyarrow as pa\nfrom sklearn import datasets\n\ndata = datasets.load_wine(as_frame=True)['data']\n\n# Create a DuckDB connection\n#conn = duckdb.connect(\"posts/in-progress/data/demo.db\")\nconn = duckdb.connect(\"data/demo.db\")\n\n# Create toy data\nduckdb.sql(\"\"\"\nDROP TABLE IF EXISTS my_table;\nCREATE TABLE my_table AS SELECT * FROM data;\nINSERT INTO my_table SELECT * FROM data;\n\"\"\")\n\n# Check that table is created\nduckdb.sql(\"SELECT * FROM my_table LIMIT 10;\")\n\n┌─────────┬────────────┬────────┬───────────────────┬───┬─────────────────┬────────┬──────────────────────┬─────────┐\n│ alcohol │ malic_acid │  ash   │ alcalinity_of_ash │ … │ color_intensity │  hue   │ od280/od315_of_dil…  │ proline │\n│ double  │   double   │ double │      double       │   │     double      │ double │        double        │ double  │\n├─────────┼────────────┼────────┼───────────────────┼───┼─────────────────┼────────┼──────────────────────┼─────────┤\n│   14.23 │       1.71 │   2.43 │              15.6 │ … │            5.64 │   1.04 │                 3.92 │  1065.0 │\n│    13.2 │       1.78 │   2.14 │              11.2 │ … │            4.38 │   1.05 │                  3.4 │  1050.0 │\n│   13.16 │       2.36 │   2.67 │              18.6 │ … │            5.68 │   1.03 │                 3.17 │  1185.0 │\n│   14.37 │       1.95 │    2.5 │              16.8 │ … │             7.8 │   0.86 │                 3.45 │  1480.0 │\n│   13.24 │       2.59 │   2.87 │              21.0 │ … │            4.32 │   1.04 │                 2.93 │   735.0 │\n│    14.2 │       1.76 │   2.45 │              15.2 │ … │            6.75 │   1.05 │                 2.85 │  1450.0 │\n│   14.39 │       1.87 │   2.45 │              14.6 │ … │            5.25 │   1.02 │                 3.58 │  1290.0 │\n│   14.06 │       2.15 │   2.61 │              17.6 │ … │            5.05 │   1.06 │                 3.58 │  1295.0 │\n│   14.83 │       1.64 │   2.17 │              14.0 │ … │             5.2 │   1.08 │                 2.85 │  1045.0 │\n│   13.86 │       1.35 │   2.27 │              16.0 │ … │            7.22 │   1.01 │                 3.55 │  1045.0 │\n├─────────┴────────────┴────────┴───────────────────┴───┴─────────────────┴────────┴──────────────────────┴─────────┤\n│ 10 rows                                                                                      13 columns (8 shown) │\n└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
  },
  {
    "objectID": "posts/in-progress/index.html#pyarrow",
    "href": "posts/in-progress/index.html#pyarrow",
    "title": "Untitled",
    "section": "PyArrow",
    "text": "PyArrow\nNow that we have a database connection, we can run SQL or use existing Python code to retrieve our data.\nDuckDB and my workflow can return and Arrow object. If your use case can’t and returns a pandas dataframe, you will need PyArrow to convert it.\n\n\ndf_pyarrow = duckdb.sql('SELECT * FROM my_table').fetch_arrow_table()\n\n# If what you are using returns pandas dataframe\ndf_pyarrow_pandas = pa.Table.from_pandas(data)"
  },
  {
    "objectID": "posts/in-progress/index.html#seemless-conversion-to-r",
    "href": "posts/in-progress/index.html#seemless-conversion-to-r",
    "title": "Untitled",
    "section": "Seemless conversion to R",
    "text": "Seemless conversion to R\nNow the wine dataset is simple enough to work with in Python. With this size, writing a csv or parquet file is even feasible.\nHowever, if you have data that is 10+ million rows, that isn’t going to be a sustainable solution. How do you transfer the data while reducing I/O constraints as much as possible?\n\nArrow\nI’ve mentioned Arrow many times throughout this post, and will continue to reference other sources for further understanding. A high level overview is that it is a standardized memory format for data, independent of language or tooling.\nIn the most basic use case of transferring a Pandas dataframe to R, there is a conversion of how it was stored in memory for Pandas and a mapping of how it will be stored in memory for an R data.frame(). To do that requires copying the data. This is called Serialization.\nWith Arrow, that definition is constant and allows for zero-copy reads without serialization.\n\n\nFinal Product\nNow this part is absolutely silly, the only piece that was missing from Danielle’s article was that py_to_r() wasn’t even needed. All I had to do was assign an r variable with the Python object with Reticulate: df <- py$df.\n\ntictoc::tic()\ndf_arrrow1 <- reticulate::py$df_pyarrow\ntictoc::toc()\n\n0.014 sec elapsed\n\ndf_arrrow1 |> \n  utils::head() |> \n  dplyr::collect()\n\n# A tibble: 6 × 13\n  alcohol malic_acid   ash alcalinity_of_ash magnesium total_phenols flavanoids\n    <dbl>      <dbl> <dbl>             <dbl>     <dbl>         <dbl>      <dbl>\n1    14.2       1.71  2.43              15.6       127          2.8        3.06\n2    13.2       1.78  2.14              11.2       100          2.65       2.76\n3    13.2       2.36  2.67              18.6       101          2.8        3.24\n4    14.4       1.95  2.5               16.8       113          3.85       3.49\n5    13.2       2.59  2.87              21         118          2.8        2.69\n6    14.2       1.76  2.45              15.2       112          3.27       3.39\n# ℹ 6 more variables: nonflavanoid_phenols <dbl>, proanthocyanins <dbl>,\n#   color_intensity <dbl>, hue <dbl>, `od280/od315_of_diluted_wines` <dbl>,\n#   proline <dbl>\n\n# If pandas to arrow needed\ndf_arrow2 <- reticulate::py$df_pyarrow_pandas\ndf_arrrow1 |> \n  utils::head() |> \n  dplyr::collect()\n\n# A tibble: 6 × 13\n  alcohol malic_acid   ash alcalinity_of_ash magnesium total_phenols flavanoids\n    <dbl>      <dbl> <dbl>             <dbl>     <dbl>         <dbl>      <dbl>\n1    14.2       1.71  2.43              15.6       127          2.8        3.06\n2    13.2       1.78  2.14              11.2       100          2.65       2.76\n3    13.2       2.36  2.67              18.6       101          2.8        3.24\n4    14.4       1.95  2.5               16.8       113          3.85       3.49\n5    13.2       2.59  2.87              21         118          2.8        2.69\n6    14.2       1.76  2.45              15.2       112          3.27       3.39\n# ℹ 6 more variables: nonflavanoid_phenols <dbl>, proanthocyanins <dbl>,\n#   color_intensity <dbl>, hue <dbl>, `od280/od315_of_diluted_wines` <dbl>,\n#   proline <dbl>\n\n\nI’m off to go work in my preferred environment…"
  },
  {
    "objectID": "posts/in-progress/index.html#use-case",
    "href": "posts/in-progress/index.html#use-case",
    "title": "Untitled",
    "section": "Use Case",
    "text": "Use Case\nFor reasons I won’t get into here, at work I needed to connect to a database in Python using existing code. From there I could stay in that environment, but I wanted to be able to work with the data in a tool that is better suited for me in R.\nI was familiar with the Apache Arrow project, and the best source I found for understanding from an R user’s perspective was This Blog Post. Danielle, at the time of writing, is a Developer Advocate at Voltron Data. A couple of statements from their website “Bridging Languages, Hardware, and People” along with “Accelerate Success with the Apache Arrow Ecosystem”.\n\nMinor Improvements\nDanielle covers all the foundations of reticulate, Apache Arrow, and getting everything set up. I was able to apply it for my use case, with one drawback. The post mentions r_to_py(), and when I tried to use py_to_r(), I had no success."
  },
  {
    "objectID": "posts/in-progress/index.html#section",
    "href": "posts/in-progress/index.html#section",
    "title": "Untitled",
    "section": "",
    "text": "As mentioned above, DuckDB is used for the toy use case. For my workflow in particular, this is where I would connect to our data with the existing Python codebase. The idea is to not re-invent the wheel for something that is already working. Rather, build a tire for that wheel that will make you go faster.\nBelow creates a toy dataset from Scikit-Learn datasets, Wine.\nNote: You can make this virtual environment lighter by not having to install sklearn and duckdb.\n\nimport duckdb \nimport pandas as pd\nimport polars as pl\nimport pyarrow as pa\nfrom sklearn import datasets\n\ndata = datasets.load_wine(as_frame=True)['data']\n\n# Create a DuckDB connection\n#conn = duckdb.connect(\"posts/in-progress/data/demo.db\")\nconn = duckdb.connect(\"data/demo.db\")\n\n# Create toy data\nduckdb.sql(\"\"\"\nDROP TABLE IF EXISTS my_table;\nCREATE TABLE my_table AS SELECT * FROM data;\nINSERT INTO my_table SELECT * FROM data;\n\"\"\")\n\n# Check that table is created\nduckdb.sql(\"SELECT * FROM my_table LIMIT 10;\")\n\n┌─────────┬────────────┬────────┬───────────────────┬───┬─────────────────┬────────┬──────────────────────┬─────────┐\n│ alcohol │ malic_acid │  ash   │ alcalinity_of_ash │ … │ color_intensity │  hue   │ od280/od315_of_dil…  │ proline │\n│ double  │   double   │ double │      double       │   │     double      │ double │        double        │ double  │\n├─────────┼────────────┼────────┼───────────────────┼───┼─────────────────┼────────┼──────────────────────┼─────────┤\n│   14.23 │       1.71 │   2.43 │              15.6 │ … │            5.64 │   1.04 │                 3.92 │  1065.0 │\n│    13.2 │       1.78 │   2.14 │              11.2 │ … │            4.38 │   1.05 │                  3.4 │  1050.0 │\n│   13.16 │       2.36 │   2.67 │              18.6 │ … │            5.68 │   1.03 │                 3.17 │  1185.0 │\n│   14.37 │       1.95 │    2.5 │              16.8 │ … │             7.8 │   0.86 │                 3.45 │  1480.0 │\n│   13.24 │       2.59 │   2.87 │              21.0 │ … │            4.32 │   1.04 │                 2.93 │   735.0 │\n│    14.2 │       1.76 │   2.45 │              15.2 │ … │            6.75 │   1.05 │                 2.85 │  1450.0 │\n│   14.39 │       1.87 │   2.45 │              14.6 │ … │            5.25 │   1.02 │                 3.58 │  1290.0 │\n│   14.06 │       2.15 │   2.61 │              17.6 │ … │            5.05 │   1.06 │                 3.58 │  1295.0 │\n│   14.83 │       1.64 │   2.17 │              14.0 │ … │             5.2 │   1.08 │                 2.85 │  1045.0 │\n│   13.86 │       1.35 │   2.27 │              16.0 │ … │            7.22 │   1.01 │                 3.55 │  1045.0 │\n├─────────┴────────────┴────────┴───────────────────┴───┴─────────────────┴────────┴──────────────────────┴─────────┤\n│ 10 rows                                                                                      13 columns (8 shown) │\n└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
  },
  {
    "objectID": "posts/2023-06-19-py-to-r/index.html",
    "href": "posts/2023-06-19-py-to-r/index.html",
    "title": "Arrow, Python, & R",
    "section": "",
    "text": "Supporting R in a Python world, using Arrow."
  },
  {
    "objectID": "posts/2023-06-19-py-to-r/index.html#use-case",
    "href": "posts/2023-06-19-py-to-r/index.html#use-case",
    "title": "Arrow, Python, & R",
    "section": "Use Case",
    "text": "Use Case\nFor reasons I won’t get into here, at work I needed to connect to a database in Python using existing code. From there I could stay in that environment, but I wanted to be able to work with the data in a tool that is better suited for me in R.\nI was familiar with the Apache Arrow project, and the best source I found for understanding from an R user’s perspective was This Blog Post. Danielle, at the time of writing, is a Developer Advocate at Voltron Data. A couple of statements from their website “Bridging Languages, Hardware, and People” along with “Accelerate Success with the Apache Arrow Ecosystem”.\n\nMinor Improvements\nDanielle covers all the foundations of reticulate, Apache Arrow, and getting everything set up. I was able to apply it for my use case, with one drawback. The post mentions r_to_py(), and when I tried to use py_to_r(), I had no success."
  },
  {
    "objectID": "posts/2023-06-19-py-to-r/index.html#setup",
    "href": "posts/2023-06-19-py-to-r/index.html#setup",
    "title": "Arrow, Python, & R",
    "section": "Setup",
    "text": "Setup\n\nDuckDB\nDuckDB is awesome. Check it out.\nAgain, this is outside the scope of this post. There is already an extensive amount of coverage on how the DB works, what it’s best for, and examples of how to use it. I mainly chose this because of it’s integration into the Apache Arrow ecosystem.\nThere are many different interfaces to install DuckDB found here: DuckDB Install.\n\n\nReticulate Config\nUsing Reticulate, we can integrate Python and R. At work, I created an R package that would allow me to use our established pipelines in python and analyze the data in R with Reticulate.\nThe intended user is already someone that is familiar with R (after all what is the point of all of this if you don’t already have {dplyr} installed?!).\n\nif(!require('reticulate')) install.packages('reticulate') \nif(!require('arrow')) install.packages('arrow') \nif(!require('tictoc')) install.packages('tictoc') # only needed for benchmark\n\nif (!reticulate::virtualenv_exists(\"demo_env\")) {\n  reticulate::virtualenv_create(\n    'demo_env'\n    , packages = c('duckdb'\n                   , 'pandas==2.0'\n                   , 'polars'\n                   , 'pyarrow'\n                   , 'scikit-learn'\n                   )\n    )\n}\n\nreticulate::use_virtualenv('demo_env')"
  },
  {
    "objectID": "posts/2023-06-19-py-to-r/index.html#section",
    "href": "posts/2023-06-19-py-to-r/index.html#section",
    "title": "Arrow, Python, & R",
    "section": "",
    "text": "As mentioned above, DuckDB is used for the toy use case. For my workflow in particular, this is where I would connect to our data with the existing Python codebase. The idea is to not re-invent the wheel for something that is already working. Rather, build a tire for that wheel that will make you go faster.\nBelow creates a toy dataset from Scikit-Learn datasets, Wine.\nNote: You can make this virtual environment lighter by not having to install sklearn and duckdb.\n\nimport duckdb \nimport pandas as pd\nimport polars as pl\nimport pyarrow as pa\nfrom sklearn import datasets\n\ndata = datasets.load_wine(as_frame=True)['data']\n\n# Create a DuckDB connection\n#conn = duckdb.connect(\"posts/in-progress/data/demo.db\")\nconn = duckdb.connect(\"data/demo.db\")\n\n# Create toy data\nduckdb.sql(\"\"\"\nDROP TABLE IF EXISTS my_table;\nCREATE TABLE my_table AS SELECT * FROM data;\nINSERT INTO my_table SELECT * FROM data;\n\"\"\")\n\n# Check that table is created\nduckdb.sql(\"SELECT * FROM my_table LIMIT 10;\")\n\n┌─────────┬────────────┬────────┬───────────────────┬───┬─────────────────┬────────┬──────────────────────┬─────────┐\n│ alcohol │ malic_acid │  ash   │ alcalinity_of_ash │ … │ color_intensity │  hue   │ od280/od315_of_dil…  │ proline │\n│ double  │   double   │ double │      double       │   │     double      │ double │        double        │ double  │\n├─────────┼────────────┼────────┼───────────────────┼───┼─────────────────┼────────┼──────────────────────┼─────────┤\n│   14.23 │       1.71 │   2.43 │              15.6 │ … │            5.64 │   1.04 │                 3.92 │  1065.0 │\n│    13.2 │       1.78 │   2.14 │              11.2 │ … │            4.38 │   1.05 │                  3.4 │  1050.0 │\n│   13.16 │       2.36 │   2.67 │              18.6 │ … │            5.68 │   1.03 │                 3.17 │  1185.0 │\n│   14.37 │       1.95 │    2.5 │              16.8 │ … │             7.8 │   0.86 │                 3.45 │  1480.0 │\n│   13.24 │       2.59 │   2.87 │              21.0 │ … │            4.32 │   1.04 │                 2.93 │   735.0 │\n│    14.2 │       1.76 │   2.45 │              15.2 │ … │            6.75 │   1.05 │                 2.85 │  1450.0 │\n│   14.39 │       1.87 │   2.45 │              14.6 │ … │            5.25 │   1.02 │                 3.58 │  1290.0 │\n│   14.06 │       2.15 │   2.61 │              17.6 │ … │            5.05 │   1.06 │                 3.58 │  1295.0 │\n│   14.83 │       1.64 │   2.17 │              14.0 │ … │             5.2 │   1.08 │                 2.85 │  1045.0 │\n│   13.86 │       1.35 │   2.27 │              16.0 │ … │            7.22 │   1.01 │                 3.55 │  1045.0 │\n├─────────┴────────────┴────────┴───────────────────┴───┴─────────────────┴────────┴──────────────────────┴─────────┤\n│ 10 rows                                                                                      13 columns (8 shown) │\n└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
  },
  {
    "objectID": "posts/2023-06-19-py-to-r/index.html#pyarrow",
    "href": "posts/2023-06-19-py-to-r/index.html#pyarrow",
    "title": "Arrow, Python, & R",
    "section": "PyArrow",
    "text": "PyArrow\nNow that we have a database connection, we can run SQL or use existing Python code to retrieve our data.\nDuckDB and my workflow can return and Arrow object. If your use case can’t and returns a pandas dataframe, you will need PyArrow to convert it.\n\n\ndf_pyarrow = duckdb.sql('SELECT * FROM my_table').fetch_arrow_table()\n\n# If what you are using returns pandas dataframe\ndf_pyarrow_pandas = pa.Table.from_pandas(data)"
  },
  {
    "objectID": "posts/2023-06-19-py-to-r/index.html#seemless-conversion-to-r",
    "href": "posts/2023-06-19-py-to-r/index.html#seemless-conversion-to-r",
    "title": "Arrow, Python, & R",
    "section": "Seemless conversion to R",
    "text": "Seemless conversion to R\nNow the wine dataset is simple enough to work with in Python. With this size, writing a csv or parquet file is even feasible.\nHowever, if you have data that is 10+ million rows, that isn’t going to be a sustainable solution. How do you transfer the data while reducing I/O constraints as much as possible?\n\nArrow\nI’ve mentioned Arrow many times throughout this post, and will continue to reference other sources for further understanding. A high level overview is that it is a standardized memory format for data, independent of language or tooling.\nIn the most basic use case of transferring a Pandas dataframe to R, there is a conversion of how it was stored in memory for Pandas and a mapping of how it will be stored in memory for an R data.frame(). To do that requires copying the data. This is called Serialization.\nWith Arrow, that definition is constant and allows for zero-copy reads without serialization.\n\n\nFinal Product\nNow this part is absolutely silly, the only piece that was missing from Danielle’s article was that py_to_r() wasn’t even needed. All I had to do was assign an r variable with the Python object with Reticulate: df <- py$df.\n\ntictoc::tic()\ndf_arrrow1 <- reticulate::py$df_pyarrow\ntictoc::toc()\n\n0.014 sec elapsed\n\ndf_arrrow1 |> \n  utils::head() |> \n  dplyr::collect()\n\n# A tibble: 6 × 13\n  alcohol malic_acid   ash alcalinity_of_ash magnesium total_phenols flavanoids\n    <dbl>      <dbl> <dbl>             <dbl>     <dbl>         <dbl>      <dbl>\n1    14.2       1.71  2.43              15.6       127          2.8        3.06\n2    13.2       1.78  2.14              11.2       100          2.65       2.76\n3    13.2       2.36  2.67              18.6       101          2.8        3.24\n4    14.4       1.95  2.5               16.8       113          3.85       3.49\n5    13.2       2.59  2.87              21         118          2.8        2.69\n6    14.2       1.76  2.45              15.2       112          3.27       3.39\n# ℹ 6 more variables: nonflavanoid_phenols <dbl>, proanthocyanins <dbl>,\n#   color_intensity <dbl>, hue <dbl>, `od280/od315_of_diluted_wines` <dbl>,\n#   proline <dbl>\n\n# If pandas to arrow needed\ndf_arrow2 <- reticulate::py$df_pyarrow_pandas\ndf_arrrow1 |> \n  utils::head() |> \n  dplyr::collect()\n\n# A tibble: 6 × 13\n  alcohol malic_acid   ash alcalinity_of_ash magnesium total_phenols flavanoids\n    <dbl>      <dbl> <dbl>             <dbl>     <dbl>         <dbl>      <dbl>\n1    14.2       1.71  2.43              15.6       127          2.8        3.06\n2    13.2       1.78  2.14              11.2       100          2.65       2.76\n3    13.2       2.36  2.67              18.6       101          2.8        3.24\n4    14.4       1.95  2.5               16.8       113          3.85       3.49\n5    13.2       2.59  2.87              21         118          2.8        2.69\n6    14.2       1.76  2.45              15.2       112          3.27       3.39\n# ℹ 6 more variables: nonflavanoid_phenols <dbl>, proanthocyanins <dbl>,\n#   color_intensity <dbl>, hue <dbl>, `od280/od315_of_diluted_wines` <dbl>,\n#   proline <dbl>\n\n\n\nI’m off to go work in my preferred environment…\nOh also, how cool is it that the Quarto document ran both R & Python in one file?!"
  },
  {
    "objectID": "posts/2023-06-15/index.html",
    "href": "posts/2023-06-15/index.html",
    "title": "Blog Reconstruction",
    "section": "",
    "text": "Hi, welcome to my site!\nI recently finished grad school, moved states, and got married. Life has been hectic and not allowed time for public work. I’m hoping to be able to tackle some public projects moving forward.\nI’m particularly excited about new developments with the Apache Arrow project, and how to bridge the gap with R and Python users. I have ADHD, which means I think in a non-linear and sporadic fashion. R will always be my true love for data analysis, with non-standard evaluation and emphasis by the Posit team on designing their API’s to be a fluid conversation with data.\nI have love for python too. Python was the first language I picked up. It taught me the beauty of understanding another way of thinking (something I again rediscovered learning about octopuses). I never excelled in math in the traditional school setting, but being able to define functions and interactively test different inputs really connected me in a way that greek letters and chalkboard never could. This is especially true for linear algebra. I don’t know that I would have any understanding if it wasn’t for numpy.\nThis is why I’m excited about polars. I love numpy and the optimization and syntax, however, it did not hold up well as a pandas backend as data grew more complex. Polars offers a syntax that requires less cognitive overhead, and the backed power of arrow and rust.\nAt work, I use these tools to be able to work in the R ecosystem for data exploration, which works for me. Additionally, I’m able to leverage arrow to convert back to python for our team’s development and machine learning environment.\nMy first (new) post will be detailing what that workflow looks like, and how easy it is to work within Quarto.\nIn the meantime, I left one (1) silly post about fantasy football. Mainly because I run that script once a year and still need it. Plus it’s always neat to be able to look back and see how far you’ve come."
  },
  {
    "objectID": "posts/2023-06-18-blog-reconstruction/index.html",
    "href": "posts/2023-06-18-blog-reconstruction/index.html",
    "title": "Blank Canvas",
    "section": "",
    "text": "Hi, welcome to my site!\nI recently finished grad school, moved states, and got married. Life has been hectic and not allowed time for public work. I’m hoping to be able to tackle some public projects moving forward.\nI’m particularly excited about new developments with the Apache Arrow project, and how to bridge the gap with R and Python users. I have ADHD, which means I think in a non-linear and sporadic fashion. R will always be my true love for data analysis, with non-standard evaluation and emphasis by the Posit team on designing their API’s to be a fluid conversation with data.\nI have love for python too. Python was the first language I picked up. It taught me the beauty of understanding another way of thinking (something I again rediscovered learning about octopuses). I never excelled in math in the traditional school setting, but being able to define functions and interactively test different inputs really connected me in a way that greek letters and chalkboard never could. This is especially true for linear algebra. I don’t know that I would have any understanding if it wasn’t for numpy.\nAt work, I use these tools to be able to work in the R ecosystem for data exploration, which works for me. Additionally, I leverage arrow to convert data back to python for our team’s development and machine learning environment.\nMy first (new) post will be detailing what that workflow looks like, and how easy it is to work within Quarto.\nIn the meantime, I left one (1) silly post about fantasy football. Mainly because I run that script once a year and still need it. Plus it’s always neat to be able to look back and see how far you’ve come."
  },
  {
    "objectID": "posts/2023-06-19-py-to-r/index.html#support-all-ways-of-thinking",
    "href": "posts/2023-06-19-py-to-r/index.html#support-all-ways-of-thinking",
    "title": "Arrow, Python, & R",
    "section": "Support All Ways of Thinking",
    "text": "Support All Ways of Thinking\nWhat is the reasoning behind this post? I love what I do, and can get an abundance of energy from projects that I’m working on. That being said, it’s incredibly frustrating using a specific tool, when I would enjoy and work faster in another tool.\n\nInsert Tired Python vs R Debate\nNothing will earn an auto-mute from me on Twitter faster than seeing a Python vs R debate. They are both fantastic tools, and each have their own strengths and weaknesses. What I find most important is to focus on how they can present themselves to a particular user. A feature I see as beneficial from R could be detrimental to another user, for a myriad of reasons.\nI support that setting up infrastructure which enables data professionals to use their tool of choice will help flourish the flow of ideas and analysis. Especially early on in the data exploration phase."
  },
  {
    "objectID": "posts/2023-08-09-reactable/index.html",
    "href": "posts/2023-08-09-reactable/index.html",
    "title": "Reactable Demo",
    "section": "",
    "text": "Hello"
  }
]